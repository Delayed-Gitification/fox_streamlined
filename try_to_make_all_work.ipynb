{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b2ec3b-3748-47b8-9acc-d44e7dc783a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up AI model...\n",
      "Using device: cpu\n",
      "Model 'wkcn/TinyCLIP-ViT-39M-16-Text-19M-YFCC15M' loaded and ready.\n",
      "Pre-computing text embeddings for all prompts...\n",
      "Text embeddings are ready.\n",
      "‚úÖ Success! Camera found at the last known IP: 192.168.68.102\n",
      "Processing at ~2 FPS. Scoring crops on motion...\n",
      "\n",
      "--- Image being scored ---\n",
      "Fox: 0.005, People Sum: 0.028\n",
      "New high fox score: 0.005\n",
      "ü¶ä Fox detected with confidence 0.005! Triggering water valve... üíß\n",
      "üì∏ Saving spray sequence to: sprinkler_sessions\\20251009_112141_555\n",
      "-> Thread started: Opening device with VID=0x16c0 PID=0x05df\n",
      "-> Device opened successfully.\n",
      "-> Sending ON command to relay #1 for 20 seconds...\n",
      "-> Relay should be ON.\n",
      "-> Sprinkler activated.\n",
      "-> Sending OFF command to relay #1...\n",
      "-> Relay should be OFF.\n",
      "-> Device closed.\n",
      "-> Sprinkler thread finished and lock released.\n",
      "-> Sprinkler deactivated.\n",
      "‚úÖ Finished saving spray sequence.\n",
      "\n",
      "--- Image being scored ---\n",
      "Fox: 0.014, People Sum: 0.036\n",
      "New high fox score: 0.014\n",
      "ü¶ä Fox detected with confidence 0.014! Triggering water valve... üíß\n",
      "üì∏ Saving spray sequence to: sprinkler_sessions\\20251009_112207_557\n",
      "-> Thread started: Opening device with VID=0x16c0 PID=0x05df\n",
      "-> Device opened successfully.\n",
      "-> Sending ON command to relay #1 for 20 seconds...\n",
      "-> Relay should be ON.\n",
      "-> Sprinkler activated.\n",
      "Stopped.\n",
      "-> Sending OFF command to relay #1...\n",
      "-> Relay should be OFF.\n",
      "-> Device closed.\n",
      "-> Sprinkler thread finished and lock released.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# IMPORTS AND INITIAL SETUP\n",
    "# ==============================================================================\n",
    "import os, cv2, time, numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Image as IPyImage\n",
    "import threading\n",
    "from queue import Queue\n",
    "import socket\n",
    "from PIL import Image\n",
    "import hid\n",
    "import torch\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "# ==============================================================================\n",
    "# RELAY & SPRINKLER CONFIG\n",
    "# ==============================================================================\n",
    "VENDOR_ID = 0x16c0\n",
    "PRODUCT_ID = 0x05df\n",
    "RELAY_TO_CONTROL = 1\n",
    "RELAY_ON_COMMAND = [0x00, 0xFF, RELAY_TO_CONTROL, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]\n",
    "RELAY_OFF_COMMAND = [0x00, 0xFD, RELAY_TO_CONTROL, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]\n",
    "sprinkler_lock = threading.Lock()\n",
    "max_crop_fraction = 0.15\n",
    "\n",
    "def sprinkler_on(t=30):\n",
    "    if not sprinkler_lock.acquire(blocking=False):\n",
    "        print(\"-> Sprinkler command ignored: An operation is already in progress.\")\n",
    "        return\n",
    "    device = None\n",
    "    try:\n",
    "        print(f\"-> Thread started: Opening device with VID=0x{VENDOR_ID:04x} PID=0x{PRODUCT_ID:04x}\")\n",
    "        device = hid.device()\n",
    "        device.open(VENDOR_ID, PRODUCT_ID)\n",
    "        print(\"-> Device opened successfully.\")\n",
    "        print(f\"-> Sending ON command to relay #{RELAY_TO_CONTROL} for {t} seconds...\")\n",
    "        device.send_feature_report(RELAY_ON_COMMAND)\n",
    "        time.sleep(0.1)\n",
    "        print(\"-> Relay should be ON.\")\n",
    "        time.sleep(t)\n",
    "        print(f\"-> Sending OFF command to relay #{RELAY_TO_CONTROL}...\")\n",
    "        device.send_feature_report(RELAY_OFF_COMMAND)\n",
    "        time.sleep(0.1)\n",
    "        print(\"-> Relay should be OFF.\")\n",
    "    except Exception as e:\n",
    "        print(f\"-> Sprinkler error: {e}\")\n",
    "    finally:\n",
    "        if device:\n",
    "            device.close()\n",
    "            print(\"-> Device closed.\")\n",
    "        sprinkler_lock.release()\n",
    "        print(\"-> Sprinkler thread finished and lock released.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# TINYCLIP MODEL SETUP\n",
    "# ==============================================================================\n",
    "# --- Configuration ---\n",
    "MODEL_ID = \"wkcn/TinyCLIP-ViT-39M-16-Text-19M-YFCC15M\"\n",
    "\n",
    "# --- Device Selection ---\n",
    "print(\"Setting up AI model...\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Load Model and Processor ---\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_ID)\n",
    "model = CLIPModel.from_pretrained(MODEL_ID)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print(f\"Model '{MODEL_ID}' loaded and ready.\")\n",
    "\n",
    "# --- Prompts and Thresholds ---\n",
    "n_people_decoys = 6\n",
    "PROMPTS = [\n",
    "    \"man\", \"woman\", \"a person walking\", \"a photograph of a person\",\n",
    "    \"people\", \"person wearing a jumper\", \"a photograph of a fox\",\n",
    "    \"a photograph of a frog\", \"an empty garden at night\", \"a car\", 'grass', 'empty', 'nothing', 'plants',\n",
    "    'blurry image of nothing', 'a photograph of a cat', 'field', 'desert',\n",
    "    \"a blurry shadow moving on the ground\", \"a blurry shape moving quickly\",\n",
    "    \"a garden chair\", \"photograph of a metal chair\", \"photograph of a door\"\n",
    "]\n",
    "FOX_SCORE_THRESHOLD = 0.14\n",
    "people_sum_thresh = 0.2\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚ú® NEW: PRE-COMPUTE TEXT EMBEDDINGS (THE OPTIMIZATION) ‚ú®\n",
    "# ==============================================================================\n",
    "print(\"Pre-computing text embeddings for all prompts...\")\n",
    "# Tokenize the prompts and move them to the selected device\n",
    "text_inputs = processor(text=PROMPTS, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "\n",
    "# Generate the text embeddings (features) once\n",
    "with torch.no_grad():\n",
    "    precomputed_text_features = model.get_text_features(**text_inputs)\n",
    "    # Normalize the features for cosine similarity calculation\n",
    "    precomputed_text_features /= precomputed_text_features.norm(dim=-1, keepdim=True)\n",
    "print(\"Text embeddings are ready.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# NETWORKING & CAMERA SETUP\n",
    "# ==============================================================================\n",
    "def _check_port(ip, port, timeout=0.5):\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.settimeout(timeout)\n",
    "    try:\n",
    "        return sock.connect_ex((ip, port)) == 0\n",
    "    finally:\n",
    "        sock.close()\n",
    "\n",
    "def find_camera_ip(default_ip='192.168.68.102', subnet='192.168.68', port=554):\n",
    "    if default_ip and _check_port(default_ip, port):\n",
    "        print(f\"‚úÖ Success! Camera found at the last known IP: {default_ip}\")\n",
    "        return default_ip\n",
    "    print(f\"üê¢ Scanning subnet {subnet}.x for a camera on port {port}...\")\n",
    "    for i in range(1, 255):\n",
    "        ip = f\"{subnet}.{i}\"\n",
    "        print(f\"\\rChecking: {ip}  \", end=\"\")\n",
    "        if _check_port(ip, port):\n",
    "            print(f\"\\n‚úÖ Found new camera IP at: {ip}\")\n",
    "            return ip\n",
    "    print(\"\\n‚ùå Camera not found on this subnet.\")\n",
    "    return None\n",
    "\n",
    "USER = \"foxyfoxy\"\n",
    "PASS = \"foxyfoxy123\"\n",
    "IP = find_camera_ip(subnet='192.168.68')\n",
    "if not IP:\n",
    "    raise RuntimeError(\"Could not find camera. Exiting.\")\n",
    "\n",
    "RTSP_LOW  = f\"rtsp://{USER}:{PASS}@{IP}:554/stream2\"\n",
    "RTSP_HIGH = f\"rtsp://{USER}:{PASS}@{IP}:554/stream1\"\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;tcp|max_delay;0|threads;1\"\n",
    "\n",
    "# ==============================================================================\n",
    "# UTILITIES AND HELPER CLASSES (UNCHANGED)\n",
    "# ==============================================================================\n",
    "# Your helper functions (ensure_dir, timestamp_str, make_mask, etc.) and\n",
    "# classes (HQSampler, FileWriter) go here. They don't need to be changed.\n",
    "def ensure_dir(p):\n",
    "    if not os.path.isdir(p):\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "def timestamp_str(ts=None):\n",
    "    if ts is None: ts = time.time()\n",
    "    return datetime.fromtimestamp(ts).strftime(\"%Y%m%d_%H%M%S_%f\")[:-3]\n",
    "USE_MASK = True\n",
    "MASK_POLYGONS = [[\n",
    "    (0.0, 1.0), (0.85, 1.0), (0.98, 0.4), (0.7, 0.35), (0.0, 0.57)\n",
    "]]\n",
    "def make_mask(shape):\n",
    "    if not USE_MASK or not MASK_POLYGONS:\n",
    "        return np.full(shape[:2], 255, dtype=np.uint8)\n",
    "    h, w = shape[:2]\n",
    "    m = np.zeros((h, w), dtype=np.uint8)\n",
    "    for poly in MASK_POLYGONS:\n",
    "        pts = np.array([[int(x*w), int(y*h)] for x, y in poly], dtype=np.int32)\n",
    "        cv2.fillPoly(m, [pts], 255)\n",
    "    return m\n",
    "def grab_latest_nonblocking(cap, max_ms=8, max_grabs=60):\n",
    "    t0 = time.time()\n",
    "    grabs = 0\n",
    "    while grabs < max_grabs:\n",
    "        if not cap.grab(): break\n",
    "        grabs += 1\n",
    "        if (time.time() - t0) * 1000.0 >= max_ms: break\n",
    "    ok, frame = cap.retrieve()\n",
    "    if not ok or frame is None: ok, frame = cap.read()\n",
    "    return ok, frame\n",
    "def encode_jpeg(img, quality=60):\n",
    "    ok, buf = cv2.imencode(\".jpg\", img, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n",
    "    return buf.tobytes() if ok else None\n",
    "def merge_contours_to_bbox(contours, min_area=150):\n",
    "    boxes = [cv2.boundingRect(c) for c in contours if cv2.contourArea(c) > min_area]\n",
    "    if not boxes: return None\n",
    "    x1 = min(b[0] for b in boxes)\n",
    "    y1 = min(b[1] for b in boxes)\n",
    "    x2 = max(b[0] + b[2] for b in boxes)\n",
    "    y2 = max(b[1] + b[3] for b in boxes)\n",
    "    return (x1, y1, x2 - x1, y2 - y1)\n",
    "def pad_and_clip_rect(x, y, w, h, pad_px, W, H):\n",
    "    x = max(0, int(x - pad_px)); y = max(0, int(y - pad_px))\n",
    "    w = int(w + 2*pad_px); h = int(h + 2*pad_px)\n",
    "    x2 = min(W, x + w); y2 = min(H, y + h)\n",
    "    return x, y, x2 - x, y2 - y\n",
    "def choose_best_by_time(history, target_ts, max_age=None):\n",
    "    best = None; best_dt = float('inf')\n",
    "    for ts, f in history:\n",
    "        dt = abs(ts - target_ts)\n",
    "        if dt < best_dt:\n",
    "            best_dt = dt; best = (ts, f)\n",
    "    if best is None or (max_age is not None and best_dt > max_age):\n",
    "        return None\n",
    "    return best\n",
    "class HQSampler:\n",
    "    def __init__(self, rtsp_url):\n",
    "        self.rtsp = rtsp_url\n",
    "        self.cap = cv2.VideoCapture(self.rtsp, cv2.CAP_FFMPEG)\n",
    "        if not self.cap.isOpened(): raise RuntimeError(\"Could not open HQ RTSP stream\")\n",
    "        try: self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        except: pass\n",
    "        self.latest = (0.0, None)\n",
    "        self.alive = True\n",
    "        self.lock = threading.Lock()\n",
    "        self.t = threading.Thread(target=self._loop, daemon=True); self.t.start()\n",
    "    def _loop(self):\n",
    "        while self.alive:\n",
    "            ok, frame = grab_latest_nonblocking(self.cap)\n",
    "            if ok and frame is not None:\n",
    "                with self.lock: self.latest = (time.time(), frame)\n",
    "            else:\n",
    "                try: self.cap.release()\n",
    "                except: pass\n",
    "                time.sleep(0.1)\n",
    "                self.cap = cv2.VideoCapture(self.rtsp, cv2.CAP_FFMPEG)\n",
    "                try: self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "                except: pass\n",
    "    def get_latest(self, max_age=1.0):\n",
    "        with self.lock: ts, fr = self.latest\n",
    "        if fr is None or (time.time() - ts) > max_age: return None\n",
    "        return fr\n",
    "    def stop(self):\n",
    "        self.alive = False\n",
    "        try: self.t.join(timeout=0.5)\n",
    "        except: pass\n",
    "        try: self.cap.release()\n",
    "        except: pass\n",
    "class FileWriter:\n",
    "    def __init__(self, maxsize=32):\n",
    "        self.q = Queue(maxsize=maxsize)\n",
    "        self.t = threading.Thread(target=self._loop, daemon=True); self.t.start()\n",
    "    def _loop(self):\n",
    "        while True:\n",
    "            item = self.q.get()\n",
    "            if item is None: break\n",
    "            path, img, quality = item\n",
    "            try: cv2.imwrite(path, img, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)])\n",
    "            except: pass\n",
    "            self.q.task_done()\n",
    "    def save_jpg(self, path, img, quality=82):\n",
    "        try: self.q.put_nowait((path, img, quality))\n",
    "        except: pass\n",
    "    def stop(self):\n",
    "        try: self.q.put(None)\n",
    "        except: pass\n",
    "        try: self.t.join(timeout=1.0)\n",
    "        except: pass\n",
    "\n",
    "# =========================\n",
    "# ‚ú® REFACTORED AI FUNCTION ‚ú®\n",
    "# =========================\n",
    "\n",
    "# This is the new, optimized scoring function that uses the pre-computed embeddings.\n",
    "def score_frame_against_precomputed_prompts(frame, text_features):\n",
    "    \"\"\"\n",
    "    Scores an OpenCV frame against pre-computed text embeddings.\n",
    "    This is much faster as it avoids re-processing text prompts.\n",
    "    \"\"\"\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(rgb_frame)\n",
    "    \n",
    "    # Process only the image\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get image features and normalize them\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Calculate similarity using matrix multiplication\n",
    "        logit_scale = model.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probs = logits_per_image.softmax(dim=-1).squeeze().cpu().numpy()\n",
    "        \n",
    "    return probs\n",
    "\n",
    "# =========================\n",
    "# Main runner (UPDATED)\n",
    "# =========================\n",
    "def run_motion_view(\n",
    "    precomputed_text_features, # ‚ú® Pass the embeddings in\n",
    "    display_width=480,\n",
    "    ui_fps=3,\n",
    "    lookback_secs=10.0,\n",
    "    save_dir=\"motion_events\",\n",
    "    jpg_quality=82,\n",
    "    event_cooldown=0.5,\n",
    "    post_sprinkler_cooldown=5\n",
    "):\n",
    "    # ... (the rest of your run_motion_view setup is the same) ...\n",
    "    ensure_dir(save_dir)\n",
    "    # ADD THESE TWO LINES HERE\n",
    "    ensure_dir(\"sprinkler_sessions\")\n",
    "    sprinkler_session_dir = None\n",
    "    ensure_dir(\"sprinkler_sessions\")\n",
    "    highest_fox_score = 0\n",
    "    cap_low = cv2.VideoCapture(RTSP_LOW, cv2.CAP_FFMPEG)\n",
    "    if not cap_low.isOpened(): raise RuntimeError(\"Could not open LOW RTSP stream\")\n",
    "    try: cap_low.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "    except: pass\n",
    "    hq = HQSampler(RTSP_HIGH)\n",
    "    fw = FileWriter()\n",
    "    roi_mask_low = None\n",
    "    hist_len = int(max(lookback_secs * ui_fps * 2, 40))\n",
    "    low_gray_history = deque(maxlen=hist_len)\n",
    "    low_color_history = deque(maxlen=hist_len)\n",
    "    interval = 1.0 / float(max(1, ui_fps))\n",
    "    next_tick = time.time()\n",
    "    sprinkler_session_dir = None\n",
    "    prev_sprinkler_locked = False\n",
    "    last_sprinkler_end_ts = 0.0\n",
    "    last_event_ts = 0.0\n",
    "    print(f\"Processing at ~{ui_fps} FPS. Scoring crops on motion...\")\n",
    "    try:\n",
    "        while True:\n",
    "            now = time.time()\n",
    "            if now < next_tick:\n",
    "                time.sleep(max(0, next_tick - now))\n",
    "                continue\n",
    "            next_tick += interval\n",
    "\n",
    "            ok_low, frame_low = grab_latest_nonblocking(cap_low)\n",
    "            if not ok_low or frame_low is None:\n",
    "                # Handle stream reconnect\n",
    "                try: cap_low.release()\n",
    "                except: pass\n",
    "                time.sleep(0.1)\n",
    "                cap_low = cv2.VideoCapture(RTSP_LOW, cv2.CAP_FFMPEG)\n",
    "                try: cap_low.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "                except: pass\n",
    "                continue\n",
    "            \n",
    "            # Resize and prep frames\n",
    "            if display_width and frame_low.shape[1] > display_width:\n",
    "                h = int(frame_low.shape[0] * (display_width / float(frame_low.shape[1])))\n",
    "                frame_low = cv2.resize(frame_low, (display_width, h), interpolation=cv2.INTER_AREA)\n",
    "            if roi_mask_low is None: roi_mask_low = make_mask(frame_low.shape)\n",
    "            gray = cv2.cvtColor(frame_low, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "            gray_roi = cv2.bitwise_and(gray, gray, mask=roi_mask_low)\n",
    "            low_gray_history.append((now, gray_roi.copy()))\n",
    "            low_color_history.append((now, frame_low.copy()))\n",
    "\n",
    "            # If a sprinkler session is active, save the current low-res frame\n",
    "            if sprinkler_session_dir:\n",
    "                hq_now = hq.get_latest()\n",
    "                if hq_now is not None:\n",
    "                    frame_filename = f\"frame_{timestamp_str(now)}.jpg\"\n",
    "                    frame_path = os.path.join(sprinkler_session_dir, frame_filename)\n",
    "                    # Save HQ frame at high quality\n",
    "                    fw.save_jpg(frame_path, hq_now.copy(), quality=10)\n",
    "\n",
    "            # Sprinkler logic (unchanged)\n",
    "            current_sprinkler_locked = sprinkler_lock.locked()\n",
    "            if current_sprinkler_locked and not prev_sprinkler_locked:\n",
    "                print(\"-> Sprinkler activated.\")\n",
    "            elif not current_sprinkler_locked and prev_sprinkler_locked:\n",
    "                last_sprinkler_end_ts = now\n",
    "                print(\"-> Sprinkler deactivated.\")\n",
    "\n",
    "                if sprinkler_session_dir:\n",
    "                    print(f\"‚úÖ Finished saving spray sequence.\")\n",
    "                    sprinkler_session_dir = None # Reset for the next event\n",
    "                \n",
    "            prev_sprinkler_locked = current_sprinkler_locked\n",
    "            if current_sprinkler_locked or (now - last_sprinkler_end_ts < post_sprinkler_cooldown):\n",
    "                continue\n",
    "                \n",
    "            # Motion detection logic (unchanged)\n",
    "            ref_low_gray = choose_best_by_time(low_gray_history, now - lookback_secs)\n",
    "            if ref_low_gray is None: continue\n",
    "            _, ref_gray = ref_low_gray\n",
    "            diff = cv2.absdiff(gray_roi, ref_gray)\n",
    "            _, motion_bin = cv2.threshold(diff, 18, 255, cv2.THRESH_BINARY)\n",
    "            motion_bin = cv2.morphologyEx(motion_bin, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "            motion_bin = cv2.dilate(motion_bin, None, iterations=1)\n",
    "            contours, _ = cv2.findContours(motion_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            union_bbox_low = merge_contours_to_bbox(contours)\n",
    "            if not union_bbox_low or (now - last_event_ts) < event_cooldown: continue\n",
    "            last_event_ts = now\n",
    "            \n",
    "            # Cropping logic (unchanged)\n",
    "            hq_now = hq.get_latest()\n",
    "            if hq_now is None: continue\n",
    "            x, y, w, h = union_bbox_low\n",
    "            Hl, Wl = frame_low.shape[:2]; Hh, Wh = hq_now.shape[:2]\n",
    "            sx, sy = Wh / float(Wl), Hh / float(Hl)\n",
    "            x_hq, y_hq, w_hq, h_hq = int(x * sx), int(y * sy), int(w * sx), int(h * sy)\n",
    "            pad_hq = int(0.07 * max(w_hq, h_hq)) + 8\n",
    "            x_hq, y_hq, w_hq, h_hq = pad_and_clip_rect(x_hq, y_hq, w_hq, h_hq, pad_hq, Wh, Hh)\n",
    "            crop_hq_now = hq_now[y_hq:y_hq+h_hq, x_hq:x_hq+w_hq]\n",
    "\n",
    "            # ==========================================================\n",
    "            # ‚ú® ADD THIS BLOCK TO DISPLAY THE IMAGE ‚ú®\n",
    "            # ==========================================================\n",
    "            print(\"\\n--- Image being scored ---\")\n",
    "            # Encode the image to JPEG format to be displayed\n",
    "            data = encode_jpeg(crop_hq_now, quality=85)\n",
    "            # Display the image inline in your notebook\n",
    "            # if data:\n",
    "            #     display(IPyImage(data=data, width=600))\n",
    "            # ==========================================================\n",
    "\n",
    "\n",
    "\n",
    "            # ‚ú® --- THE CRITICAL CHANGE: USE THE OPTIMIZED FUNCTION --- ‚ú®\n",
    "            probabilities = score_frame_against_precomputed_prompts(\n",
    "                crop_hq_now,\n",
    "                precomputed_text_features # Pass in the pre-calculated embeddings\n",
    "            )\n",
    "\n",
    "            # ... (the rest of your logic for displaying, printing scores, and triggering the sprinkler is the same)\n",
    "            \n",
    "            # Find the score specifically for the \"fox\" prompt\n",
    "            fox_index = PROMPTS.index(\"a photograph of a fox\")\n",
    "            fox_score = probabilities[fox_index]\n",
    "            decoys = np.sum(probabilities[:n_people_decoys])\n",
    "\n",
    "            print(f\"Fox: {fox_score:.3f}, People Sum: {decoys:.3f}\")\n",
    "\n",
    "            ev_dir = os.path.join(save_dir)\n",
    "            ensure_dir(ev_dir)\n",
    "            fw.save_jpg(os.path.join(ev_dir,  f\"{timestamp_str(now)}_fox_score_{fox_score:.3f}.jpg\"), crop_hq_now, jpg_quality)\n",
    "\n",
    "            if fox_score > highest_fox_score:\n",
    "                print(f\"New high fox score: {fox_score:.3f}\")\n",
    "                highest_fox_score = fox_score\n",
    "\n",
    "            if (fox_score > FOX_SCORE_THRESHOLD and decoys < people_sum_thresh) or decoys > 10000:\n",
    "                print(f\"ü¶ä Fox detected with confidence {fox_score:.3f}! Triggering water valve... üíß\")\n",
    "\n",
    "                session_ts = timestamp_str(now)\n",
    "                sprinkler_session_dir = os.path.join(\"sprinkler_sessions\", session_ts)\n",
    "                ensure_dir(sprinkler_session_dir)\n",
    "                print(f\"üì∏ Saving spray sequence to: {sprinkler_session_dir}\")\n",
    "                \n",
    "                sprinkler_time = 20\n",
    "                threading.Thread(target=sprinkler_on, args=(sprinkler_time,), daemon=True).start()\n",
    "                \n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped.\")\n",
    "    finally:\n",
    "        cap_low.release()\n",
    "        hq.stop()\n",
    "        fw.stop()\n",
    "\n",
    "# =========================\n",
    "# ‚ú® Run it (UPDATED CALL) ‚ú®\n",
    "# =========================\n",
    "if __name__ == '__main__':\n",
    "    run_motion_view(\n",
    "        precomputed_text_features=precomputed_text_features, # ‚ú® Pass the embeddings in\n",
    "        ui_fps=2,\n",
    "        lookback_secs=10.0,\n",
    "        save_dir=\"motion_events\",\n",
    "        jpg_quality=82,\n",
    "        event_cooldown=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459ab63-0769-4ce6-99ef-795295d0e03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851e4dc-957d-4061-8554-50e20eb04b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tinyclip_env)",
   "language": "python",
   "name": "tinyclip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
